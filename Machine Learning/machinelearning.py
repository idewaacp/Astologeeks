# -*- coding: utf-8 -*-
"""MachineLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lo_j8LLpQnqQb11rh3WX9oUW0ZFtCa8j
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from datetime import datetime
from dateutil.relativedelta import relativedelta

df = pd.read_csv('horoscope_saved.csv')
df = df.drop(columns='date')
#df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')
df

df.info()

df.describe(include = 'all')

df.isnull().sum()

df.shape

"""**Visualisasi Data**"""

#Univariated analysis sign

f = plt.figure(figsize=(42,12))
f.add_subplot(1,2,1)
sns.countplot(df['sign'])
plt.show()

#Univariated analysis category

f = plt.figure(figsize=(24,12))
f.add_subplot(1,2,1)
sns.countplot(df['category'])
plt.show()

"""**Data Preperation**"""

# convert to lowercase
df['horoscope'] = df['horoscope'].str.lower()

#from nltk.corpus import stopwords #comment jika Error dan gunakan 2 sintaks dibawah
import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop = set(stopwords.words('english'))
df['horoscope_stopword'] = df['horoscope'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

df.head()

#label encoding

# Import label encoder 
from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder() 
df['sign']= label_encoder.fit_transform(df['sign']) 
df['category']= label_encoder.fit_transform(df['category'])

df

horo = df['horoscope_stopword'].values
labels = df[['sign', 'category']].values

#memisahkan data training dan validasi (data validasi hanya terdiri 20% dari total dataset)
horo_latih, horo_test, labels_latih, labels_test = train_test_split(horo, labels, test_size=0.2)

#fungsi tokenizer
filt = '!"#$%&()*+.,-/:;=?@[\]^_`{|}~ '

tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>', filters = filt)
tokenizer.fit_on_texts(horo_latih)
tokenizer.fit_on_texts(horo_test)
 
sekuens_latih = tokenizer.texts_to_sequences(horo_latih)
sekuens_test = tokenizer.texts_to_sequences(horo_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

word2index = tokenizer.word_index
print(len(word2index))

import json

with open('word2index.json', 'w') as fp:
    json.dump(word2index, fp)

"""**Modeling**"""

#implementasi callback

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and 
       logs.get('val_accuracy')>0.9):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

#Arsitektur model machine learning dengan menggunakan embedding dan LSTM
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=13000, output_dim=32),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])
model.summary()

#compiler
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 10
history = model.fit(padded_latih, labels_latih, epochs=num_epochs, 
                    validation_data=(padded_test, labels_test), verbose=2, callbacks=[callbacks])

def toSequence(sentence):
  pad = []
  for stc in sentence.split():
    if stc.lower() in word2index.keys(): 
      pad.append(word2index[stc.lower()])
    else: 
      continue
  return pad

pad = toSequence('Look forward to a year of fun, mischief, and wild inventiveness! Youre bursting with fresh ideas.')
len(pad)
model.predict([pad])

#[1, 0] = Aries/Birthday

model.save("machinelearning.h5")

"""Save Model to TFjs"""

!pip install tensorflowjs

saved_model_path = '/content/mymodel/'
tf.saved_model.save(model, saved_model_path)

!tensorflowjs_converter \
  --input_format=tf_saved_model \
  /content/mymodel/ \
  /content/modeltfjs